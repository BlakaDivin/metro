#!/usr/bin/python3

import os
import os.path
import sys
import glob
import datetime
sys.path.append(os.path.join(os.path.dirname(os.path.realpath(__file__)),"../modules"))

from metro_support import lockFile, countFile
from db import *

# these variables are used for building:

builds = ( )
arches = ( )
subarches = ( )

# these variables, if defined, are used for repo management (cleaning, etc.):

all_builds = ( )
all_arches = ( )
all_subarches = ( )

cfgfile = os.path.join(os.path.expanduser("~"),".buildbot")
if os.path.exists(cfgfile):
    exec(open(cfgfile, "rb").read())
else:
    print("""
Create a ~/.buildbot file that contains something like this (python syntax):

builds = (
	"funtoo-experimental",
	"funtoo-current",
	"funtoo-current-hardened",
	"funtoo-stable",
)

arches = (
	"x86-32bit",
	"x86-64bit",
	"sparc-64bit",
	"pure64"
)

subarches = ( 
	"atom_32",
	"atom_64",
	"corei7",
	"corei7-pure64",
	"generic_32", 
	"i686", 
	"athlon-xp",
	"pentium4",
	"core2_32",
	"amd64-k8_32",
	"amd64-k8",
	"amd64-k10",
	"core2_64",
	"generic_64",
	"generic_64-pure64",
)

def map_build(build, subarch, full, full_date):
	# arguments refer to last build...
	if full == True:
		buildtype = "freshen"
	else:
		buildtype = "full"
	if subarch in [ "corei7", "corei7-pure64", "generic_64",  "generic_64-pure64" ]:
		buildtype = buildtype + "+openvz"
	return buildtype
""")
    sys.exit(1)

if len(all_builds) == 0:
	# if the all_variables are not defined, inherit values from the non-all vars:
	all_builds = builds
	all_arches = arches
	all_subarches = subarches

class SubArch(dbobject):
	@classmethod
	def _makeTable(cls,db):
		cls.db = db
		cls.__table__ = Table('subarch', db.metadata,
			Column('id', Integer, primary_key = True),
			Column('date', DateTime, index=True),
			Column('date_str', String, index=True),
			Column('path', String, index=True),
			Column('build', String, index=True),
			Column('arch', String, index=True),
			Column('subarch', String, index=True),
			Column('failcount', Integer, index=True),
			Column('full_date', DateTime, index=True),
			Column('full_date_str', String, index=True),
			Column('do_build', Boolean, index=True)
		)

class BuildDir(dbobject):
	@classmethod
	def _makeTable(cls,db):
		cls.db = db
		cls.__table__ = Table('bdir', db.metadata,
			Column('id', Integer, primary_key = True),
			Column('date', DateTime, index=True),
			Column('path', String, index=True),
			Column('build', String, index=True),
			Column('arch', String, index=True),
			Column('subarch', String, index=True),
			Column('date_str', String, index=True),
			Column('complete', Boolean, index=True),
			Column('full', Boolean, index=True)
		)

class Snapshot(dbobject):
	@classmethod
	def _makeTable(cls,db):
		cls.db = db
		cls.__table__ = Table('snapshot', db.metadata,
			Column('id', Integer, primary_key = True),
			Column('path', String, index=True),
			Column('build', String, index=True),
		)

class RepositoryDatabase(Database):
	__database__ = "sqlite:///cleaner.db"
	def __init__(self):
		Database.__init__(self,[BuildDir, Snapshot, SubArch])
		self.associate()
	def associate(self):
		Database.associate(self,self.__database__)

from subprocess import Popen, PIPE

process = Popen(["%s/../metro" % os.path.dirname(os.path.realpath(__file__)), "-k", "path/mirror"], stdout=PIPE, stderr=PIPE)
out = process.stdout.read()
ret = process.wait()
if ret:
	print("Error calling metro for mirror path.")
else:
	initial_path = out.decode("ascii").strip()

if __name__ == "__main__":
	if os.path.exists("cleaner.db"):
		os.unlink("cleaner.db")
	db = RepositoryDatabase()
	session = db.session
	for build in all_builds:
		if not os.path.exists("%s/%s" % (initial_path, build)):
			continue
		snapdir = "%s/%s/snapshots" % ( initial_path, build )
		if os.path.isdir(snapdir) and not os.path.islink(snapdir):
			for match in glob.glob("%s/portage-*.tar.xz" % snapdir):
				basename = os.path.basename(match)
				if basename == "portage-current.tar.xz":
					continue
				sna = Snapshot()
				sna.path = match
				sna.build = build
				session.add(sna)
		for arch in all_arches:
			if not os.path.exists("%s/%s/%s" % ( initial_path, build, arch )):
				continue
			for subarch in all_subarches:
				path = "%s/%s/%s/%s" % (initial_path, build, arch, subarch)
				if not os.path.exists(path):
					continue
				most_recent = None
				most_recent_str = None
				most_recent_full = None
				most_recent_full_str = None
				failpath = path + "/.control/.failcount"
				if not os.path.exists(failpath):
					failcount = 0
				else:
					fc = countFile(failpath)
					failcount = fc.count
				for instance in os.listdir(path):
					try:
						date = datetime.datetime.strptime(instance,"%Y-%m-%d")
					except ValueError:
						continue
					ipath = "%s/%s" % ( path, instance )
					if not os.path.isdir(ipath):
						continue
					complete = False
					for match in glob.glob("%s/stage3*.tar.*" % ipath):
						complete = True
						break
					bdir = BuildDir()
					bdir.path = ipath
					bdir.date = date
					bdir.date_str = instance
					bdir.build = build
					bdir.arch = arch
					bdir.subarch = subarch
					bdir.complete = complete
					if complete:
						for match in glob.glob("%s/stage1*.tar.*" % ipath):
							bdir.full = True
							break
					session.add(bdir)
					if complete and ( most_recent == None or most_recent < bdir.date ):
						most_recent = bdir.date
						most_recent_str = bdir.date_str
						if bdir.full:
							most_recent_full = bdir.date
							most_recent_full_str = bdir.date_str
				sa = SubArch()
				sa.build = build
				sa.arch = arch
				sa.subarch = subarch
				sa.date = most_recent
				sa.date_str = most_recent_str
				sa.full_date = most_recent_full
				sa.full_date_str = most_recent_full_str
				sa.failcount = failcount
				sa.path = path
				# is subarch in our list of things to build, or just to maintain (ie. clean, for main repo)?
				if build in builds and arch in arches and subarch in subarches:
					sa.do_build = True
				else:
					sa.do_build = False
				session.add(sa)

	session.commit()
now = datetime.datetime.now()
stale_days = 2
# more than 3 fails and we remove the build from our rotation:
fail_count = 3
def find_build(q):
	for x in q:
		# if something is newer than 4 days old, it is not considered stale, so we skip over it:
		if x.date != None and now - x.date < datetime.timedelta(days=stale_days):
			continue	
		# otherwise, we have found the next thing we should try to build. Output important info to stdout:

		# drop it from our build rotation if the build has failed too many consecutive times:
		fcfilepath = x.path+"/.control/.failcount"
		if os.path.exists(fcfilepath):
			fcfile = countFile(fcfilepath)
			if fcfile.exists() and fcfile.count >= fail_count:
				sys.stderr.write("# Build at %s has failed more than %s times; skipping...\n" % (x.path, fail_count))
				continue
		# skip it if it is currently being built....
		tsfilepath = x.path+"/.control/.multi_progress"
		if os.path.exists(tsfilepath):
			tsfile = lockFile(tsfilepath)
			# ensure lockFile is not stale. The exists() method will clean it up automatically if it is:
			if tsfile.exists():
				sys.stderr.write("# Build at %s in progress, skipping...\n" % x.path)
				continue
		# output: build subarch was-last-build-full(had-a-stage-1)(boolean) date
		print("build=%s" % x.build)
		print("subarch=%s" % x.subarch)
		print("fulldate=%s" % x.full_date_str)
		print("nextdate=%s" % datetime.datetime.strftime(datetime.datetime.now(), "%Y-%m-%d"))
		print("failcount=%s" % x.failcount)
		mb = map_build(x.build, x.subarch, x.full_date == x.date and x.date != None, x.full_date_str)
		# handle case where map_build returns "full+openvz":
		if type(mb) == str:
			mb = mb.split("+")
		# handle case where map_build returns ("full", "openvz"):
		print("target=%s" % mb[0])
		if len(mb) > 1:
			print("extras='%s'" % " ".join(mb[1:]))
		else:
			print("extras=''")
		sys.exit(0)

if len(sys.argv) > 1 and sys.argv[1] == "clean":
	for build in all_builds:
		# first -- remove any more than 3 complete builds, starting with oldest, of course:
		for arch in all_arches:
			for subarch in all_subarches:
				out = session.query(BuildDir).filter_by(build=build).filter_by(arch=arch).filter_by(subarch=subarch).filter_by(complete=True).order_by(BuildDir.date_str).all()
				for x in out[0:-3]:
					print(("rm -rf %s" % x.path))
				for x in out[-3:]:
					print(("# keeping %s" % x.path))
		# next, remove any more than 2 snapshots:
		sna = session.query(Snapshot).filter_by(build=build).order_by(Snapshot.path).all()
		for x in sna[0:-3]:
			print(("rm %s*" % x.path))
		for x in sna[-2:]:
			print(("# keeping %s" % x.path))
	# Now, look at incomplete builds. Clean them out when they're stale and not the most recent build.
	for x in session.query(BuildDir).filter_by(complete=False):
		# ignore non-stale builds for cleaning -- they could be in-progress...
		y = session.query(SubArch).filter_by(subarch=x.subarch).filter_by(arch=x.arch).filter_by(build=x.build).first()
		if x.date != None and now - x.date > datetime.timedelta(days=stale_days) and y.date != x.date:
			# don't zap most recent...
			print(("rm -rf %s* # not complete and stale, not most recent build" % x.path))
		else:
			print("# keeping %s" % x.path)

elif len(sys.argv) > 1 and sys.argv[1] == "nextbuild":
	sa = session.query(SubArch)
	myfail = 0
	while myfail < failcount:
		# we start with failcount of zero, and prioritize not-yet-built stages:
		empties = sa.filter(SubArch.__table__.c.do_build == True).filter(SubArch.__table__.c.date == None).filter(SubArch.__table__.c.build.in_(builds)).filter_by(failcount=myfail)
		find_build(empties)
		# if we can't find one, we look for a failcount of zero, but prioritize by date:
		oldies = sa.filter(SubArch.__table__.c.do_build == True).filter(SubArch.__table__.c.date != None).filter(SubArch.__table__.c.build.in_(builds)).filter_by(failcount=myfail).order_by(SubArch.__table__.c.date)
		find_build(oldies)
		myfail += 1
		# if no builds are found, we increment failcount, and try again:
	# THIS PART IS DISABLED. IF A BUILD IS BEYOND ITS FAILCOUNT, IT IS OUT OF ROTATION UNTIL SOMEONE MANUALLY INTERVENES:
	# if our loop didn't present a build, we ignore date, look for all builds with failcount >= our max, and then order by failcount, and pick a build:
	#baddies = sa.filter(SubArch.__table__.c.do_build == True).filter(SubArch.__table__.c.build.in_(builds)).filter(SubArch.__table__.c.failcount >= failcount).order_by(SubArch.__table__.c.failcount.asc())
	#find_build(baddies)
	sys.exit(1)
elif len(sys.argv) ==2 and sys.argv[1] == "empties":
	empties = session.query(SubArch).filter(SubArch.__table__.c.do_build == True).filter(SubArch.__table__.c.date == None).filter(SubArch.__table__.c.build.in_(builds))
	for x in empties:
		print(x.path)
	
